\section{Training und Validation der Klassifizierer}

Die in Sektion~\ref{classifiers} beschrieben Klassifizierer Random Forest Classifier, Single Vector Maschine (SVM) und ein k-Nearest-Classifier werden verwendet.
Die Implementierung dieser Klassifizierer und andere Funktionalitäten werden durch die Maschine-Learning-Bibliothek scikit-learn~\cite{scikit-learn} zur Verfügung gestellt.
Der Prozess der Optimierung und das Training der Klassifizierer wird durch die Bibliothek hyperopt-sklearn~\cite{Komer2019} realisiert. 
Dabei kann der Trainingsprozess in folgende Schritte unterteilt werden:

\begin{enumerate}
    \item \textbf{Aufteilen des Datensatzes}: Für das Training wird der Datensatz aus Sektion~\ref{dataset_analysis} in ein Trainings- und Validationsdatensatz aufgeteilt. Dabei werden 70 \% der Datenpunkte dem Trainingsdatensatz und die restlichen 30 \% dem Validationsdatensatz zugewiesen.
    Die Aufteilung wird nach dem Zufallsprinzip durchgeführt. Die Rollen, die als Python String dargestellt werden, werden durch einen sklearn LabelEncoder ein kategorischer Integer-Wert zugewiesen. 
    \item \textbf{Initialisierung der Klassifizierer}: Die ausgewählten Klassifizierer werden mit den Standardwerten ihrer Hyperparameter initialisiert.
    Zusätzlich wird für jedes Modell einen Zahlenwert zwischen 0.0 und 1.0 definiert. Dieses gibt an, mit welcher Wahrscheinlichkeit die jeweilige Instanz in einer Trainingsiteration ausgewählt wird. Falls notwendig, wird bei der Instanziierung der Klassifizierer ein zusätzlicher Schritt für die Skalierung der Werte der Datenpunkte durchgeführt.
    Dies ist der Fall bei SVM oder KNN, da bei unskalierten Datenwerte die Klassifikationsleistung von SVM und KNN negativ beeinträchtigt werden kann. Dabei wird der durch sklearn zur Verfügung gestellte StandardScaler verwendet, der Features standardisiert, indem dieser den Mittelwert entfernt und die Datenpunkte auf Einheitsvarianz skaliert. Für den Random Forrest Classifier wird die Skalierung der Datenpunkte ebenfalls angewandt, da dessen Leistung davon nicht negativ beeinträchtigt wird.
    Die Instanzen der Klassifizierer werden mit den Standardwerten für die Hyperparameter initialisiert, die von hyperopt zur Verfügung gestellt werden.
    \item \textbf{Starten des Trainings}: Wie bereits erwähnt, wird das Training und Optimieren der Modelle durch hyperopt-sklearn automatisiert durchgeführt. Die Instanzen der Klassifizierer werden in einer Instanz der Klasse HyperoptEstimator gebündelt, welche als Abstraktionsschicht das Training und das Optimieren der Hyperparameter kapselt. Bei dessen Instanziierung wird ebenfalls bestimmt, wie viele Iterationen die Modelle für das Training insgesamt durchlaufen müssen, nach welcher Metrik die Iterationen evaluiert und nach welchen Algorithmus die Permutationen der Hyperparameterwerte bestimmt werden. 
    Für das Training werden 20 Iteration hergenommen und die Evaluation jeder Iteration erfolgt durch Ermittelung des \textit{f1}-Wertes. Für die Ermittelung der nächsten Konfiguration an Hyperparameter-Werten wird Tree Of Parzen Estimators verwendet.
    \item \textbf{Kreuzvalidierung der besten Iteration}: Mit einem k-Wert von 5 wird die Kreuzvalidierung mit dem Trainingsdatensatz und dem \textit{f1}-Wert als Evaluierungsmetrik an dem optimierten Model durchgeführt.
\end{enumerate}