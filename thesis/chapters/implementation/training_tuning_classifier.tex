\section{Training und Validation der Klassifizierer}

Die in Sektion~\ref{classifiers} beschriebenen Klassifizierer, Random Forest Classifier, Support Vector Machine (SVM) und k-Nearest-Classifier (KNN) werden verwendet.
Die Implementierung dieser Klassifizierer und andere Funktionalitäten werden durch die Machine Learning Bibliothek scikit-learn~\cite{scikit-learn} zur Verfügung gestellt.
Der Prozess der Optimierung und das Training der Klassifizierer wird durch die Bibliothek hyperopt-sklearn~\cite{Komer2019} realisiert. 
Dabei kann der Trainingsprozess in folgende Schritte unterteilt werden:

\begin{enumerate}
    \item \textbf{Aufteilen des Datensatzes}: Für das Training wird der Datensatz aus Sektion~\ref{dataset_analysis} in einen Trainings- und Validationsdatensatz aufgeteilt. Dabei werden 70 \% der Datenpunkte dem Trainingsdatensatz und die restlichen 30 \% dem Validationsdatensatz zugewiesen. Die Rollen, die als Python String dargestellt werden, werden durch einen sklearn LabelEncoder ein kategorischer Integer-Wert zugewiesen. 
    \item \textbf{Initialisierung der Klassifizierer}: Die Instanzen der Klassifizierer werden mit den Standardwerten für die Hyperparameter initialisiert, die von hyperopt-sklearn zur Verfügung gestellt werden.
    Zusätzlich wird für jedes Modell einen Zahlenwert zwischen 0.0 und 1.0 definiert. Dieses gibt an, mit welcher Wahrscheinlichkeit das jeweilige Modell in einer Trainingsiteration ausgewählt wird. Falls notwendig, wird bei der Instanziierung der Klassifizierer ein zusätzlicher Schritt für die Skalierung der Werte der Datenpunkte durchgeführt.
    Dies ist der Fall bei SVM oder KNN, da bei unskalierten Datenwerten die Klassifikationsleistung von SVM und KNN negativ beeinträchtigt werden kann. Dabei wird der durch sklearn zur Verfügung gestellte StandardScaler verwendet, der Features standardisiert, indem dieser den Mittelwert entfernt und die Datenpunkte auf Einheitsvarianz skaliert. Für den Random Forrest Classifier wird die Skalierung der Datenpunkte ebenfalls angewandt, obwohl dessen Leistung davon nicht negativ beeinträchtigt wird.
    \item \textbf{Starten des Trainings}: Wie bereits erwähnt, wird das Training und Optimieren der Modelle durch hyperopt-sklearn automatisiert durchgeführt. Die Instanzen der Klassifizierer werden in einer Instanz der Klasse HyperoptEstimator gebündelt, welche als Abstraktionsschicht das Training und das Optimieren der Hyperparameter kapselt. Bei dessen Instanziierung wird ebenfalls bestimmt, wie viele Iterationen die Modelle für das Training insgesamt durchlaufen müssen, nach welcher Metrik die Iterationen evaluiert und nach welchem Algorithmus die Permutationen der Hyperparameter-Werte bestimmt werden. 
    Für das Training werden 20 Iterationen hergenommen und die Evaluation jeder Iteration erfolgt durch Ermittelung des \textit{f1}-Wertes. Für die Ermittelung der nächsten Konfiguration an Hyperparameter-Werten wird Tree of Parzen Estimators verwendet.
    \item \textbf{Kreuzvalidierung der besten Iteration}: Mit einem k-Wert von 5 wird die Kreuzvalidierung mit dem Validationsdatensatz und dem \textit{f1}-Wert als Evaluierungsmetrik an dem optimierten Model durchgeführt.
\end{enumerate}